{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c24eaf8-2f4e-4bec-89aa-ae6c02ac2430",
   "metadata": {},
   "source": [
    "# Case Study of the'TinyStories' Dataset\n",
    "The 'TinyStories' dataset is a large dataset that was generated using AI story request prompts and responses. It helps facilitate quick fine-tuning of models that were trained with real-world data - such as LLaMA. As this is a large dataset, and this data was generated with the help of AI, the data may have unintentionally been skewed or biased during generation. It is essential to examine the contents of this dataset and whether it is suitable to our applications content-moderation objectives with regard to literacy, mental-health, and creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062c2ff4-3e24-475b-95aa-3fbfbb3a284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "176d203f-fb16-4fd2-b16d-f8dad4516505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, countDistinct\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "from pyspark.accumulators import AccumulatorParam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c06983af-d363-42cb-99a0-15879a9e89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a127284-6e5d-4520-b1fe-17fa615bc395",
   "metadata": {},
   "source": [
    "## Setting up the Distributed Processing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad87510-bb69-4cad-a5e7-e079a9e1fcd6",
   "metadata": {
    "kernelspec": {
     "display_name": "Python 3 (ipykernel)",
     "language": "python",
     "name": "python3"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "ipython",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "python",
     "nbconvert_exporter": "python",
     "pygments_lexer": "ipython3",
     "version": "3.11.11"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating EMR Serverless connection..\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>00frarnisqpud90a</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"https://j-00frarnisqpud90a.dashboard.emr-serverless.us-east-1.amazonaws.com/?authToken=eDAx_aGHfIUexS3UADEXgEYYkwsE7DbehkDPgvFzsbDC3nhq5n2uCptySTXSpzomspP6lof-Wb6_ktOc1fMjynZeIcWgOpqcQdp8FgopC2z_gvXWaPQERUVZ1s-zSE1RCqFwtowrdYBVOnfIK_MH2tC3wkD1PyJJ-9qhppsMtAqRdhcM3Jpiwk7gpPWNELTEwen3EnGZ5DNfS8k63NbWHqohSz0J5zHOG6fQOGNR0PfGApIcX-QWYS9Y7d5WehOjlG72Qgq3IyRht9Mf2kSxPbl3Wh_bQpRawYyrvnFpTzb0t4Ty-_DUqdmfH0nKuT1b2JKL4uXzknxG0MYjwzKxvqRW1-eroBcHVuUaEtOwo5vegy-FZLQvnPiIw9cEHuaU89oRwsccnqwzlLM2BWls8P20X03KnFJxRgDd-4AiIr2xTo0Ftm-PJxQtr5LBxdiA19AWvaonCShcMMeghbmKuTXlg4tVjpM2Pq5OG2ciSukaw_Ht5bhK7fALJ23FVJcuQ5hTDcizflEIsVc7sy7BZtBgqTYoQaWvSTKG3_7Gx1YLgcms1j3PJjPc1XRZOGiii-9a7Xi9QmiljMOMBT8BnLIaB9tLToBUe4YCtWf6RDXYpXULmqwO0mu5fEoQjYLwzWBE5xTYWCNc6TX5xiuJFUAbHp0n1QUKKChp1BXdmhKzcvOE_ga7u2bdMf70R0raxeXB3NT5FcoYhoj4uDaIRmpJCT_X5ENXsUssRZGuuacrne2f7B_cLBdcwAOHiCLgj4SYdjo2MM6CilsiIav3DicC_fNZq6G-_2O6YYwpvZDBaMlcf-M2dGtADgwCLfCbiUe9MWAu3le-etSw-xlpqQ3jLttUnOHAAWkjQhM_1iSA2KDcskeOEuvfHFqe-aFmU422SFGKOSNDGKYXtoh_apNHAG_hz0hqPpcyQqNQibN3hQ.eyJraWQiOiJBUUlCQUhnTVJ1MlZyR2FFajR3bTc2dEZqMThGMUsyVFdZbkk4WXpxS0lRamg5YTZHZ0dpTUd6eUVXRU9hZWt6b0xKdzZLcUVBQUFBb2pDQm53WUpLb1pJaHZjTkFRY0dvSUdSTUlHT0FnRUFNSUdJQmdrcWhraUc5dzBCQndFd0hnWUpZSVpJQVdVREJBRXVNQkVFRFBUQ2RlRmFVUGxNYjdIT1VRSUJFSUJiOVMyQm1lMkhZVU53VUtWQ0ZMTjUwS2JuS01EQkhWdURDQjNJSDVQcjRPL3lsek9wQXBOUHV5NlV1YzRDaW5OSUZkWlg3RFJaMFY4UjYwaGtUaU8wQjBxVTAwRkVNRDVVWmdjelpndnoxaGdYVlJONGlmTmFEbXYyOXc9PSJ9\">Link</a></td><td><a target=\"_blank\" href=\"https://j-00frarnisqpud90a.dashboard.emr-serverless.us-east-1.amazonaws.com/logs/SPARK_DRIVER/stderr.gz?authToken=eDAx_fsqyuQ6FK3Oz3SHd7dF7KZOnABM4Zms4v8h1gZnP8UH05zYS6ylaw5bMZibOpmXXZOEqQzHJoT6FPsPjnbUdQbM89HTpSM12mlsEfJryaaV6-S1ADvVfch6Ubszco9TvQSsuySxBYWbo5XFm_4jry1dAjlLzJ0W1dhSd1rLF-sHR8Jz2AFo7ffGe0IqULhN9oRQbeeeqEflApJnlbowJkK8xvPWmZ64_n5QUV8KTgEgXyz0PZ5-5I53C5MpiuSDj47uJa-kWml8Uq22qxzI282qJucQxP4haa7-RZjjZgQ6eVaD0zEe-CLEAkQ69__Pou4tyDev8nW134cZcPn5UdHRg-HQJAKac1q7aEjSbLkkaEfFykRbIuD9kbmP1edgW67rblwG6rQxOIXNKfZO3AaWQraexI4GM5QReDNbTHnrm09BVvyPdTKxdXrdKDSa3Pn-oWcGAYFJQ66mTjNK4pF_Yf9g0gNrZ-KkTtzkxGepGNiI1sNUks3wJov-ljVFhTUBlLtXaR-V9_nFUe016doxGBWHdcHbJA0dh3ADezsnCVPYaVrwU7hn3KAVaOT7zuQs84P1RRAwoB33lNt-S_M1O5mKQB24vOSlwcdVNAYblZH-XmBmFvDOIW23nC075nI5rtgChCSjCnSvX19kn_sol1ntwJMWGmJBJ_qECvz-LozkR-UFEZXmj8P72_eDN3Vhe28eEOzNsDXY1rL6HgrOhIWfHaUmXQYisVO9F5u4HVqTgpWaVihvRKL60jz-T4euSjWhcdehlfdtS1KalnP418SXvdCMoCg69fVrVqdQhhV-QQYV4hpZ3-nQtpg7LzcaFfmwWPtgS4-6LEeruM06VoxOrT3G4D7kTvPQsRvjZ7y0DO4fxZhUq5TAAPrkSK3CJ9nft7yGedRKw36kbeUE4zl28FrSPKbL0HA.eyJraWQiOiJBUUlCQUhnTVJ1MlZyR2FFajR3bTc2dEZqMThGMUsyVFdZbkk4WXpxS0lRamg5YTZHZ0hud01XSG00RnBZRVN6V2NwNFZFK2NBQUFBb2pDQm53WUpLb1pJaHZjTkFRY0dvSUdSTUlHT0FnRUFNSUdJQmdrcWhraUc5dzBCQndFd0hnWUpZSVpJQVdVREJBRXVNQkVFREExNFBTcTlXYXN4UENmajNRSUJFSUJiUzhGM3FwUW9obmwvTUt5bkpQWnM3T0FSSkRNa0JzSHhtSDdWS0pyYWtNZ3g1Wml1OVZJTlhBODRGQ2QwRWJHcHRTTnZmb3YzSmJjeEErQmFrdFFIOS9hMWZ4cU95YTJyV2puREsvQkkyNlA2Qk1QVTA5SVpZQnNOV3c9PSJ9\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbf3c82d0b0471281a442a99981c062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%load_ext sagemaker_studio_analytics_extension.magics\n",
    "%sm_analytics emr-serverless connect --application-id 00fra2001bfrlm09 --language python --emr-execution-role-arn arn:aws:iam::597161074694:role/service-role/AmazonEMR-ServiceRole-20250211T131858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d6dda3-922e-4a43-bd46-44fc1f95060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/28 23:47:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# connecting to the spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"64g\") \\\n",
    "    .appName('spark') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a931d-75ee-47a5-b493-b699924dde3b",
   "metadata": {},
   "source": [
    "# Statistical Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76440b2b-338d-4c36-970a-a24e86d3ca5b",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7035db01-cc5e-4af1-975b-81b60cf42655",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"skeskinen/TinyStories-GPT4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f199f8-6faf-4c7c-9312-2d50435d3f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['story', 'summary', 'source', 'prompt', 'words', 'features'],\n",
       "        num_rows: 2745100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120ad9e-80ea-449b-9132-8cfc2ff045a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.createDataFrame(data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df75014-1d5f-4484-8ecc-7dbd649859c6",
   "metadata": {},
   "source": [
    "## Mental Health\n",
    "As for mental-health, goals may be defined in objective terms by inferring the emotions, subjects, topics, genres, or any commonly used keywords related to mental-health within the data. For this purpose, we can use the list of words and narrative features provided within the prompts provided to the AI in the training data for each row in the dataset. By counting the occurences of the 'words' and 'features' columns used within the prompt, we can make some insights of the mental-health objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d61094c5-1189-48aa-bc05-34a79f867ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCountAccumulator(AccumulatorParam):\n",
    "    def zero(self, value):\n",
    "        return {}  # Initialize an empty dictionary\n",
    "\n",
    "    def addInPlace(self, accum, value):\n",
    "        # Ensure value is split into words if it's a string\n",
    "        if isinstance(value, str):\n",
    "            value = value.split()  # Split the string into words\n",
    "\n",
    "        for word in value:  # Iterate through the list of words\n",
    "            if word is not None and word.strip():  # Check for non-empty words\n",
    "                word = word.strip()  # Remove leading/trailing whitespace\n",
    "                if word in accum:\n",
    "                    accum[word] += 1\n",
    "                else:\n",
    "                    accum[word] = 1\n",
    "        return accum\n",
    "\n",
    "    def merge(self, accum1, accum2):  # Combine multiple dictionaries\n",
    "        for key, value in accum2.items():\n",
    "            if key is not None and key.strip():  # Check for non-empty keys\n",
    "                if key not in accum1:\n",
    "                    accum1[key] = value\n",
    "                else:\n",
    "                    accum1[key] += value\n",
    "        return accum1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8dedae9d-3f0d-4cad-bd6c-14015dcbe7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_count_unique(strings):\n",
    "    if strings is None:\n",
    "        return None\n",
    "    normalized_strings = [s.strip().lower() for s in strings if s is not None and s.strip()]\n",
    "    return normalized_strings\n",
    "# the sparkerized function to normalize the words/features for comparison\n",
    "normalize_count_udf = udf(normalize_and_count_unique, ArrayType(StringType())) # Assuming string type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a009cc-b815-46a6-8035-8f19df9a09a6",
   "metadata": {},
   "source": [
    "### Narrative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fafc262-54fc-4e58-85b8-e61ed5952ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_accumulator = spark.sparkContext.accumulator(\n",
    "    {}, WordCountAccumulator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc876450-a892-490c-b7b2-837d480c0056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/29 01:29:42 WARN TaskSetManager: Stage 27 contains a task of very large size (223671 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/03/29 01:29:59 WARN TaskSetManager: Stage 28 contains a task of very large size (223671 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Ensure processed as lists of words\n",
    "train = train.withColumn(\"normalized_features\", normalize_count_udf(col(\"features\")))\n",
    "train.foreach(lambda row: features_accumulator.add(\n",
    "    {word: 1 for word in (row[\"normalized_features\"].split() if isinstance(row[\"normalized_features\"], str) else row[\"normalized_features\"])\n",
    "     if word is not None and word.strip()}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fbf14c1b-3bdf-4412-b33b-3d2124ba357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialogue         16\n",
       "badending        16\n",
       "twist            16\n",
       "conflict         16\n",
       "foreshadowing    16\n",
       "moralvalue       16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_occurences = pd.Series(features_accumulator.value)\n",
    "feature_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dc61e-afde-4215-83ed-f19f66d71218",
   "metadata": {},
   "source": [
    "### Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71fa2e-0088-42cc-9f25-76a349eb8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_accumulator = spark.sparkContext.accumulator(\n",
    "    {}, WordCountAccumulator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d20150-8f57-48f4-9344-0c321ab5de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/29 00:21:38 WARN TaskSetManager: Stage 1 contains a task of very large size (223671 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "train = train.withColumn(\"normalized_words\", normalize_count_udf(col(\"words\")))\n",
    "train.foreach(lambda row: words_accumulator.add(\n",
    "    {word: 1 for word in (row[\"normalized_words\"].split() if isinstance(row[\"normalized_words\"], str) else row[\"normalized_words\"])\n",
    "     if word is not None and word.strip()}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d2737b45-5d55-43eb-891a-ea43257b740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight     16\n",
       "grill     16\n",
       "bright    16\n",
       "kick      16\n",
       "bridge    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_occurrences = pd.Series(words_accumulator.value)\n",
    "word_occurrences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd998ba-ff46-4b64-8e2b-ee6204b0f96c",
   "metadata": {},
   "source": [
    "## Creativity\n",
    "Objectively speaking, creativity is a hard goal to define as it can be objectively defined in a multitude of way, as are the aforementioned topics of literacy and mental-health. However, many people might agree that creativity is somehow unique. Therefore, it may be possible to define the goal of creativity by understanding the level of variance in the models responses to similar prompts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb81cf-68dc-4308-bb0b-0a0458b37be1",
   "metadata": {},
   "source": [
    "# Statistical Analysis\n",
    "In this section the statistical metrics calculated from the training data is analyzed and visualized for making insights with regards to the stated objectives. Furthermore, given the complexity in understanding the level of literacy from the data - as no 'literacy level' column is within the data - a language model is used to classify the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ecc21-098d-496b-80bb-eca1404a95c0",
   "metadata": {},
   "source": [
    "## Literacy\n",
    "WonderWords' literacy goals may be defined in objective terms by classifying whether the responses are at a lower or a higher reading level. As our application is targeting a youth demographic, utilizing the categorization system used in most libraries and school systems will help illustrate whether the training data is biased towards a specific set of reading levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6c85e-b99d-4ff3-9be2-c9bc02a020dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6807b95c-f612-4cd4-8d4a-efc8b2f12962",
   "metadata": {},
   "source": [
    "## Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8cad3c-88a6-4591-9600-a2bbc899f490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d33ce727-9f78-4d50-81f5-f7825acbcdc9",
   "metadata": {},
   "source": [
    "## Creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd172f7b-6208-4017-adad-c53ceb4909fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
