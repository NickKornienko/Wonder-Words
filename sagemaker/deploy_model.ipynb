{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516e33ee-83c2-4403-9b34-8efcd21cc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:06:32.723843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serve.builder.model_builder import ModelBuilder\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "from safetensors.torch import load_file\n",
    "import torch\n",
    "from sagemaker.serve.mode.function_pointers import Mode\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "from sagemaker.serve import InferenceSpec\n",
    "import boto3\n",
    "from sagemaker.serve import CustomPayloadTranslator\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from sagemaker.serve.spec.inference_spec import InferenceSpec\n",
    "from transformers import pipeline\n",
    "from sagemaker.serve import ModelServer\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "sagemaker_session = Session()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# get execution role\n",
    "# please use execution role if you are using notebook instance or update the role arn if you are using a different role\n",
    "execution_role = get_execution_role() if get_execution_role() is not None else \"your-role-arn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09518978-2d7e-4a4d-ae56-586a4e245020",
   "metadata": {},
   "source": [
    "# Using Sagemaker's 'ModelBuilder' Class to Format and Deploy the PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d47b14-ba91-4d79-b144-8fe00a55f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = 'Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would understand. The story should use the verb \"buy\", the noun \"passport\" and the adjective \"pretty\". The story has the following features: the story should contain at least one dialogue. Remember to only use simple words!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aeeeb0c-d086-4b47-969c-b569f18a8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = \"Once upon a time, there was a pretty girl named Lily. She loved to travel and see new places. One day, Lily decided she wanted to go on a big trip. But first, she needed to buy a passport. Lily went to the passport place with her mom. She said, 'Mom, can you help me buy a passport, please?' Her mom smiled and said, 'Of course, Lily. Let's do it together.' They filled out the papers and took a nice photo. A few days later, Lily got her passport in the mail. She was so happy! Now she could go on her big trip. She packed her bags and said goodbye to her friends. With her pretty new passport, Lily was ready to explore the world.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09d0d4-5df2-4c47-adba-6c9022c8d18c",
   "metadata": {},
   "source": [
    "## Inference Object for Handling Input/Output of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b3518b-dfd1-433e-a84e-db76a4d45469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom inference spec with hugging face pipeline\n",
    "class InferenceSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        return pipeline(model=\"Alexis-Az/Story-Generation-LlaMA-3.1-8B-10k\")\n",
    "        \n",
    "    def invoke(self, input, model):\n",
    "        return model(input)\n",
    "    \n",
    "    \n",
    "inf_spec = InferenceSpec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd53be0-a1e5-497f-8ef1-e2ce231b1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py310\n"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.g4dn.4xlarge'\n",
    "image = image_uris.retrieve(region=region, framework='huggingface', image_scope='inference', version='4.28.1', base_framework_version='pytorch2.0.0', instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78498cf9-8118-4c33-a9bb-068c249479e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "value: str = \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\"\n",
    "schema = SchemaBuilder(value,\n",
    "            {\"generated_text\": \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\\\nDaniel: Hello, Girafatron!\\\\nGirafatron: Hi, Daniel. I was just thinking about how magnificent giraffes are and how they should be worshiped by all.\\\\nDaniel: You and I think alike, Girafatron. I think all animals should be worshipped! But I guess that could be a bit impractical...\\\\nGirafatron: That\\'s true. But the giraffe is just such an amazing creature and should always be respected!\\\\nDaniel: Yes! And the way you go on about giraffes, I could tell you really love them.\\\\nGirafatron: I\\'m obsessed with them, and I\\'m glad to hear you noticed!\\\\nDaniel: I\\'\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94daee4d-4f95-4240-a5d1-a2ce070a02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4f81815-af0c-42b7-9985-d8d0d0133fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder(\n",
    "    mode=Mode.SAGEMAKER_ENDPOINT,\n",
    "    inference_spec=inf_spec,\n",
    "    role_arn=execution_role,\n",
    "    image_uri=image,\n",
    "    schema_builder=schema,\n",
    "    env_vars={\"HF_TASK\":\"text-generation\"},\n",
    "    model_server=ModelServer.TORCHSERVE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c0e5758-8da5-421d-9547-61ef0942f54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBuilder(model_path='/tmp/sagemaker/model-builder/ceb062beef4211efa3eaaa57039344d3', role_arn='arn:aws:iam::597161074694:role/service-role/SageMaker-ExecutionRole-20250210T145384', sagemaker_session=None, name='model-name-ceb063c2ef4211efa3eaaa57039344d3', mode=<Mode.SAGEMAKER_ENDPOINT: 3>, shared_libs=[], dependencies={'auto': False}, env_vars={'HF_TASK': 'text-generation'}, log_level=10, content_type=None, accept_type=None, s3_model_data_url=None, instance_type='ml.c5.xlarge', schema_builder=SchemaBuilder(\n",
       "input_serializer=<sagemaker.base_serializers.StringSerializer object at 0x7f2df8cf5dd0>\n",
       "output_serializer=<sagemaker.serve.builder.schema_builder.JSONSerializerWrapper object at 0x7f2df5dd4050>\n",
       "input_deserializer=<sagemaker.base_deserializers.StringDeserializer object at 0x7f2e03f57cd0>\n",
       "output_deserializer=<sagemaker.base_deserializers.JSONDeserializer object at 0x7f2f94906510>), model=None, inference_spec=<__main__.InferenceSpec object at 0x7f2e1b0b27d0>, image_uri='763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04', image_config=None, vpc_config=None, model_server=<ModelServer.TORCHSERVE: 1>, model_metadata=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98ff6c7f-8b2c-40ea-bac7-199ac0882343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: INFO:     Either inference spec or model is provided. ModelBuilder is not handling MLflow model input\n",
      "ModelBuilder: INFO:     Skipping auto detection as the image uri is provided 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n",
      "ModelBuilder: DEBUG:     Uploading the model resources to bucket=sagemaker-us-east-1-597161074694, key_prefix=huggingface-pytorch-inference-2025-02-20-05-01-33-690.\n",
      "Uploading model artifacts: 100%|██████████████████████████| 8546/8546 [00:00<00:00, 67562.08bytes/s]\n",
      "ModelBuilder: DEBUG:     Model resources uploaded to: s3://sagemaker-us-east-1-597161074694/huggingface-pytorch-inference-2025-02-20-05-01-33-690/serve.tar.gz\n"
     ]
    }
   ],
   "source": [
    "aws_model = model_builder.build(role_arn=execution_role, sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9313e38-b5b5-42d3-b5af-8d6161c57785",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = aws_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.4xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93753e83-d521-4e8a-8b38-8a1861b964e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"model_fn() takes 1 positional argument but 2 were given\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-inference-2025-02-20-05-01-39-355 in account 597161074694 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWrite a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would understand. The story should use the verb \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, the noun \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m and the adjective \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m. The story has the following features: the story should contain at least one dialogue. Remember to only use simple words!\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"model_fn() takes 1 positional argument but 2 were given\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-inference-2025-02-20-05-01-39-355 in account 597161074694 for more information."
     ]
    }
   ],
   "source": [
    "predictor.predict('Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would understand. The story should use the verb \"buy\", the noun \"passport\" and the adjective \"pretty\". The story has the following features: the story should contain at least one dialogue. Remember to only use simple words!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e601e-e185-4e16-8692-c5277f1bcfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
